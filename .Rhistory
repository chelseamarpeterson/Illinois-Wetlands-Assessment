colnames(area.df) = c("water_cutoff","perm_level","buf_dist","area","delta_area",
"leveed_only","non_intersect_only","below_flood_only",
"leveed_and_non_intersect","leveed_and_below_flood",
"non_intersect_and_below_flood","leveed_non_intersect_below_flood",
"pond","emergent","forest")
n = 1
for (i in 1:n.w) {
for (j in 1:n.p) {
for (k in 1:n.b) {
# assign policy scenario labels
area.df[n,"water_cutoff"] = water.regimes[i]
area.df[n,"perm_level"] = perm.levels[j]
area.df[n,"buf_dist"] = buf.dists[k]
# create column for flow permanence and buffer distance combination
buf.ws.col = paste("Waters_Intersect", perm.abrvs[j], buf.dists[k], sep="_")
# get all water regimes up to the ith and then identify rows with insufficient flooding
wrs1 = water.regimes[1:i]
wrs.inds1 = !(ws.df$WATER_REGI %in% wrs1)
# identify all wetland polygons that (1) don't meet the flood frequency cutoff,
# (2) occur within a leveed area, or (3) don't intersect the WOTUS buffer
area1 = sum(ws.df[which(wrs.inds1 | (ws.df$Within_Levee == 1 | ws.df[,buf.ws.col] == 0)),"Area_Ha"])
area.df[n,"area"] = area1
# calculate the incremental increase in non-WOTUS area relative to less strict
# flood frequency cutoff
if (i < n.w) {
wrs2 = water.regimes[1:(i+1)]
wrs.inds2 = !(ws.df$WATER_REGI %in% wrs2)
area2 = sum(ws.df[which(wrs.inds2 | (ws.df$Within_Levee == 1 | ws.df[,buf.ws.col] == 0)),"Area_Ha"])
area.df[n,"delta_area"] = area1 - area2
} else {
area.df[n,"delta_area"] = 0
}
# calculate cumulative non-WOTUS area by reason for loss of jurisdiction
area.df[n,"leveed_only"] = sum(ws.df[which(!wrs.inds1 & (ws.df$Within_Levee == 1 & ws.df[,buf.ws.col] == 1)),"Area_Ha"])
area.df[n,"non_intersect_only"] = sum(ws.df[which(!wrs.inds1 & (ws.df$Within_Levee == 0 & ws.df[,buf.ws.col] == 0)),"Area_Ha"])
area.df[n,"leveed_and_non_intersect"] = sum(ws.df[which(!wrs.inds1 & (ws.df$Within_Levee == 1 & ws.df[,buf.ws.col] == 0)),"Area_Ha"])
area.df[n,"below_flood_only"] = sum(ws.df[which(wrs.inds1 & (ws.df$Within_Levee == 0 & ws.df[,buf.ws.col] == 1)),"Area_Ha"])
area.df[n,"leveed_and_below_flood"] = sum(ws.df[which(wrs.inds1 & (ws.df$Within_Levee == 1 & ws.df[,buf.ws.col] == 1)),"Area_Ha"])
area.df[n,"non_intersect_and_below_flood"] = sum(ws.df[which(wrs.inds1 & (ws.df$Within_Levee == 0 & ws.df[,buf.ws.col] == 0)),"Area_Ha"])
area.df[n,"leveed_non_intersect_below_flood"] = sum(ws.df[which(wrs.inds1 & (ws.df$Within_Levee == 1 & ws.df[,buf.ws.col] == 0)),"Area_Ha"])
# calculate cumulative non-WOTUS wetland area for each wetland type
pond.df = ws.df[which(ws.df$WETLAND_TYPE == "Freshwater Pond"),]
emerg.df = ws.df[which(ws.df$WETLAND_TYPE == "Freshwater Emergent Wetland"),]
forest.df = ws.df[which(ws.df$WETLAND_TYPE == "Freshwater Forested/Shrub Wetland"),]
wrs.inds.p = !(pond.df$WATER_REGI %in% wrs1)
wrs.inds.e = !(emerg.df$WATER_REGI %in% wrs1)
wrs.inds.f = !(forest.df$WATER_REGI %in% wrs1)
area.df[n,"pond"] = sum(pond.df[which(wrs.inds.p | (pond.df$Within_Levee == 1 | pond.df[,buf.ws.col] == 0)),"Area_Ha"])
area.df[n,"emergent"] = sum(emerg.df[which(wrs.inds.e | (emerg.df$Within_Levee == 1 | emerg.df[,buf.ws.col] == 0)),"Area_Ha"])
area.df[n,"forest"] = sum(forest.df[which(wrs.inds.f | (forest.df$Within_Levee == 1 | forest.df[,buf.ws.col] == 0)),"Area_Ha"])
# increment counter
n = n + 1
}
}
}
# check area equality across non-WOTUS criteria
round(area.df$area - area.df$leveed_only - area.df$non_intersect_only - area.df$below_flood_only - area.df$leveed_and_non_intersect - area.df$leveed_and_below_flood - area.df$non_intersect_and_below_flood - area.df$leveed_non_intersect_below_flood,1)
## step 5: estimate max contribution of stream permanence and buffer distances to area uncertainty
# buffer uncertainty across flow permanence levels
area.buf.stats.df = area.df %>%
group_by(water_cutoff, perm_level) %>%
summarize(mean = mean(area),
min = min(area),
max = max(area))
area.buf.stats.df$range = area.buf.stats.df$max - area.buf.stats.df$min
round(max(area.buf.stats.df$range))
# flow uncertainty across buffer distance levels
area.perm.stats.df = area.df %>%
group_by(water_cutoff, buf_dist) %>%
summarize(mean = mean(area),
min = min(area),
max = max(area))
area.perm.stats.df$range = area.perm.stats.df$max - area.perm.stats.df$min
round(max(area.perm.stats.df$range))
## step 6: calculate statistics for each wetland type
area.type.df = area.df[,c("water_cutoff","buf_dist","perm_level","pond","emergent","forest")]
area.type.melt = melt(area.type.df,
id.vars=c("water_cutoff","buf_dist","perm_level"),
variable.name="type",value.name="area")
type.stats.df = area.type.melt %>%
group_by(water_cutoff, type) %>%
summarize(mean = mean(area),
min = min(area),
max = max(area))
## step 7: calculate statistics for each water regime (Table 1)
# estimate cumulative area at each wetland flood-frequency cutoff
area.stats.df = area.df %>%
group_by(water_cutoff) %>%
summarize(mean = mean(area),
min = min(area),
max = max(area))
area.stats.df$study = "This study"
# estimate cumulative area as percentage of total state area
percent.stats.df = area.stats.df
percent.stats.df[,c("min","mean","max")] = area.stats.df[,c("min","mean","max")]/total.state.area.ha*100
# estimate incremental area at each wetland flood-frequency cutoff
area.del.stats.df = area.df %>%
group_by(water_cutoff) %>%
summarize(mean = mean(delta_area),
min = min(delta_area),
max = max(delta_area))
# estimate incremental area as percentage of total state area
perc.del.stats.df = area.del.stats.df
perc.del.stats.df[,c("min","mean","max")] = area.del.stats.df[,c("min","mean","max")]/total.state.area.ha*100
# print neatly for tables in order of increasing wetland flood frequency
area.mean.sort = sort(area.stats.df$mean, index.return=T)
area.stats.df[area.mean.sort$ix,]
percent.stats.df[area.mean.sort$ix,]
area.del.stats.df[area.mean.sort$ix,]
round(data.frame(percent.stats.df[area.mean.sort$ix,c("mean","min","max")]),2)
round(data.frame(perc.del.stats.df[area.mean.sort$ix,c("mean","min","max")]),8)
# read in levin (2002) and Simmmons et al. (2024) estimates
setwd(path_to_gitrepo)
ls.df = read.csv("Area_Estimates/Previous_Studies/Fixed_Estimates_Acres.csv", sep=",")
ls.df.area = ls.df[which(ls.df$type == "area"),-which(colnames(ls.df) %in% c("type","unit"))]
View(ls.df.area)
# Levin et al. (2002) estimate
levin.est.df = ls.df.area[which(ls.df.area$study == "Levin et al. (2002)"),]
levin.est.df[,c("mean","min","max")] = levin.est.df[,c("mean","min","max")]/AcPerHa
View(area.stats.df)
colnames(area.stats.df)
levin.est.df = ls.df.area[which(ls.df.area$study == "Levin et al. (2002)"),]
levin.est.df[,c("mean","min","max")] = levin.est.df[,c("mean","min","max")]/AcPerHa
for (i in 1:n.w) {
levin.est.df$water_cutoff = rev(water.regimes)[i]
area.stats.df = rbind(area.stats.df, levin.est.df[,colnames(area.stats.df)])
}
sim.est.df = ls.df.area[which(ls.df.area$study == "Simmons et al. (2024)"),]
sim.est.df[,c("mean","min","max")] = sim.est.df[,c("mean","min","max")]/AcPerHa
for (i in 1:n.w) {
sim.est.df$water_cutoff = rev(water.regimes)[i]
area.stats.df = rbind(area.stats.df, sim.est.df[,colnames(area.stats.df)])
}
lan.est.df = ls.df.area[which(ls.df.area$study == "Lane et al. (2025)"),]
lan.est.df[,c("mean","min","max")] = lan.est.df[,c("mean","min","max")]/AcPerHa
for (i in 1:n.w) {
lan.est.df$water_cutoff = rev(water.regimes)[i]
area.stats.df = rbind(area.stats.df, lan.est.df[,colnames(area.stats.df)])
}
colnames(area.stats.df)
rev(water.regimes)
nrdc.est.df[,c("water_cutoff","study","mean","min","mean")]
i = 1
# NRDC (2025) estimate
nrdc.est.df = ls.df.area[which(ls.df.area$study == "Devine et al. (2025)"),]
nrdc.est.df[,c("mean","min","max")] = nrdc.est.df[,c("mean","min","max")]/AcPerHa
nrdc.est.df$water_cutoff = rev(water.regimes)[i]
nrdc.est.df[,c("water_cutoff","study","mean","min","mean")]
path_to_nwi_data = "C:/Users/Chels/OneDrive - University of Illinois - Urbana/Illinois Wetlands Risk Assessment/Results/NWI_Data"
path_to_gitrepo = "C:/Users/Chels/OneDrive - University of Illinois - Urbana/Illinois Wetlands Risk Assessment/Public-Repo"
library(ggplot2)
library(reshape2)
library(patchwork)
library(dplyr)
library(remotes)
library(ggpattern)
library(gridExtra)
# conversions
AcPerHa = 2.47105
################################################################################
# Figure 1 & Table 1: calculate and plot area of wetlands that could be
# non-jurisdictional based on levee, wetland flood frequency, and flow permanence
# criteria
setwd(path_to_nwi_data)
## step 1: estimate total area of wetlands in the state (397,186 ha)
base.df = read.csv("IL_WS_Step10_WaterRegime.csv")
total.state.area.ha = sum(base.df$Area_Ha)
# check for area agreement
total.state.area.ha
sum(base.df$Area_Acres)/AcPerHa
## step 2: read in table for wetlands above 0.10 ac (396,572 ha)
ws.df = read.csv("IL_WS_Step11_AreaThreshold.csv")
# check for area agreement
sum(ws.df$Area_Ha)
sum(ws.df$Area_Acres/AcPerHa)
## step 3: make character vectors for policy scenarios
# water regimes / Wetland Flood-Frequency Cutoffs
water.regimes = c("Permanently Flooded","Intermittently Exposed",
"Semipermanently Flooded","Seasonally Flooded/Saturated",
"Seasonally Flooded","Seasonally Saturated",
"Temporary Flooded","Intermittently Flooded")
water.reg.labels = c("Permanently Flooded","Intermittently Exposed",
"Semipermanently Flooded","Seasonally Flooded/Saturated",
"Seasonally Flooded","Seasonally Saturated",
"Temporarily Flooded","Intermittently Flooded")
n.w = length(water.regimes)
# stream flow permanence criteria
perm.levels = c("Perennial","Intermittent","Ephemeral")
perm.abrvs = c("1","2","3")
n.p = length(perm.abrvs)
# make vectors for buffer scenarios
buf.dists = c("1","10","20","100")
buf.cols = paste("buf", buf.dists, sep="")
n.b = length(buf.dists)
# step 4: create data frame with to estimate non-WOTUS areas in various categories,
# e.g. total, by reason for loss of jurisdiction, and by wetland type
area.df = data.frame(matrix(nrow=n.w*n.p*n.b, ncol=15))
colnames(area.df) = c("water_cutoff","perm_level","buf_dist","area","delta_area",
"leveed_only","non_intersect_only","below_flood_only",
"leveed_and_non_intersect","leveed_and_below_flood",
"non_intersect_and_below_flood","leveed_non_intersect_below_flood",
"pond","emergent","forest")
n = 1
for (i in 1:n.w) {
for (j in 1:n.p) {
for (k in 1:n.b) {
# assign policy scenario labels
area.df[n,"water_cutoff"] = water.regimes[i]
area.df[n,"perm_level"] = perm.levels[j]
area.df[n,"buf_dist"] = buf.dists[k]
# create column for flow permanence and buffer distance combination
buf.ws.col = paste("Waters_Intersect", perm.abrvs[j], buf.dists[k], sep="_")
# get all water regimes up to the ith and then identify rows with insufficient flooding
wrs1 = water.regimes[1:i]
wrs.inds1 = !(ws.df$WATER_REGI %in% wrs1)
# identify all wetland polygons that (1) don't meet the flood frequency cutoff,
# (2) occur within a leveed area, or (3) don't intersect the WOTUS buffer
area1 = sum(ws.df[which(wrs.inds1 | (ws.df$Within_Levee == 1 | ws.df[,buf.ws.col] == 0)),"Area_Ha"])
area.df[n,"area"] = area1
# calculate the incremental increase in non-WOTUS area relative to less strict
# flood frequency cutoff
if (i < n.w) {
wrs2 = water.regimes[1:(i+1)]
wrs.inds2 = !(ws.df$WATER_REGI %in% wrs2)
area2 = sum(ws.df[which(wrs.inds2 | (ws.df$Within_Levee == 1 | ws.df[,buf.ws.col] == 0)),"Area_Ha"])
area.df[n,"delta_area"] = area1 - area2
} else {
area.df[n,"delta_area"] = 0
}
# calculate cumulative non-WOTUS area by reason for loss of jurisdiction
area.df[n,"leveed_only"] = sum(ws.df[which(!wrs.inds1 & (ws.df$Within_Levee == 1 & ws.df[,buf.ws.col] == 1)),"Area_Ha"])
area.df[n,"non_intersect_only"] = sum(ws.df[which(!wrs.inds1 & (ws.df$Within_Levee == 0 & ws.df[,buf.ws.col] == 0)),"Area_Ha"])
area.df[n,"leveed_and_non_intersect"] = sum(ws.df[which(!wrs.inds1 & (ws.df$Within_Levee == 1 & ws.df[,buf.ws.col] == 0)),"Area_Ha"])
area.df[n,"below_flood_only"] = sum(ws.df[which(wrs.inds1 & (ws.df$Within_Levee == 0 & ws.df[,buf.ws.col] == 1)),"Area_Ha"])
area.df[n,"leveed_and_below_flood"] = sum(ws.df[which(wrs.inds1 & (ws.df$Within_Levee == 1 & ws.df[,buf.ws.col] == 1)),"Area_Ha"])
area.df[n,"non_intersect_and_below_flood"] = sum(ws.df[which(wrs.inds1 & (ws.df$Within_Levee == 0 & ws.df[,buf.ws.col] == 0)),"Area_Ha"])
area.df[n,"leveed_non_intersect_below_flood"] = sum(ws.df[which(wrs.inds1 & (ws.df$Within_Levee == 1 & ws.df[,buf.ws.col] == 0)),"Area_Ha"])
# calculate cumulative non-WOTUS wetland area for each wetland type
pond.df = ws.df[which(ws.df$WETLAND_TYPE == "Freshwater Pond"),]
emerg.df = ws.df[which(ws.df$WETLAND_TYPE == "Freshwater Emergent Wetland"),]
forest.df = ws.df[which(ws.df$WETLAND_TYPE == "Freshwater Forested/Shrub Wetland"),]
wrs.inds.p = !(pond.df$WATER_REGI %in% wrs1)
wrs.inds.e = !(emerg.df$WATER_REGI %in% wrs1)
wrs.inds.f = !(forest.df$WATER_REGI %in% wrs1)
area.df[n,"pond"] = sum(pond.df[which(wrs.inds.p | (pond.df$Within_Levee == 1 | pond.df[,buf.ws.col] == 0)),"Area_Ha"])
area.df[n,"emergent"] = sum(emerg.df[which(wrs.inds.e | (emerg.df$Within_Levee == 1 | emerg.df[,buf.ws.col] == 0)),"Area_Ha"])
area.df[n,"forest"] = sum(forest.df[which(wrs.inds.f | (forest.df$Within_Levee == 1 | forest.df[,buf.ws.col] == 0)),"Area_Ha"])
# increment counter
n = n + 1
}
}
}
# check area equality across non-WOTUS criteria
round(area.df$area - area.df$leveed_only - area.df$non_intersect_only - area.df$below_flood_only - area.df$leveed_and_non_intersect - area.df$leveed_and_below_flood - area.df$non_intersect_and_below_flood - area.df$leveed_non_intersect_below_flood,1)
## step 5: estimate max contribution of stream permanence and buffer distances to area uncertainty
# buffer uncertainty across flow permanence levels
area.buf.stats.df = area.df %>%
group_by(water_cutoff, perm_level) %>%
summarize(mean = mean(area),
min = min(area),
max = max(area))
area.buf.stats.df$range = area.buf.stats.df$max - area.buf.stats.df$min
round(max(area.buf.stats.df$range))
# flow uncertainty across buffer distance levels
area.perm.stats.df = area.df %>%
group_by(water_cutoff, buf_dist) %>%
summarize(mean = mean(area),
min = min(area),
max = max(area))
area.perm.stats.df$range = area.perm.stats.df$max - area.perm.stats.df$min
round(max(area.perm.stats.df$range))
## step 6: calculate statistics for each wetland type
area.type.df = area.df[,c("water_cutoff","buf_dist","perm_level","pond","emergent","forest")]
area.type.melt = melt(area.type.df,
id.vars=c("water_cutoff","buf_dist","perm_level"),
variable.name="type",value.name="area")
type.stats.df = area.type.melt %>%
group_by(water_cutoff, type) %>%
summarize(mean = mean(area),
min = min(area),
max = max(area))
## step 7: calculate statistics for each water regime (Table 1)
# estimate cumulative area at each wetland flood-frequency cutoff
area.stats.df = area.df %>%
group_by(water_cutoff) %>%
summarize(mean = mean(area),
min = min(area),
max = max(area))
area.stats.df$study = "This study"
# estimate cumulative area as percentage of total state area
percent.stats.df = area.stats.df
percent.stats.df[,c("min","mean","max")] = area.stats.df[,c("min","mean","max")]/total.state.area.ha*100
# estimate incremental area at each wetland flood-frequency cutoff
area.del.stats.df = area.df %>%
group_by(water_cutoff) %>%
summarize(mean = mean(delta_area),
min = min(delta_area),
max = max(delta_area))
# estimate incremental area as percentage of total state area
perc.del.stats.df = area.del.stats.df
perc.del.stats.df[,c("min","mean","max")] = area.del.stats.df[,c("min","mean","max")]/total.state.area.ha*100
# print neatly for tables in order of increasing wetland flood frequency
area.mean.sort = sort(area.stats.df$mean, index.return=T)
area.stats.df[area.mean.sort$ix,]
percent.stats.df[area.mean.sort$ix,]
area.del.stats.df[area.mean.sort$ix,]
round(data.frame(percent.stats.df[area.mean.sort$ix,c("mean","min","max")]),2)
round(data.frame(perc.del.stats.df[area.mean.sort$ix,c("mean","min","max")]),8)
## step 8: compare results to previous studies
# read in levin (2002) and Simmmons et al. (2024) estimates
setwd(path_to_gitrepo)
ls.df = read.csv("Area_Estimates/Previous_Studies/Fixed_Estimates_Acres.csv", sep=",")
ls.df.area = ls.df[which(ls.df$type == "area"),-which(colnames(ls.df) %in% c("type","unit"))]
# Levin et al. (2002) estimate
levin.est.df = ls.df.area[which(ls.df.area$study == "Levin et al. (2002)"),]
levin.est.df[,c("mean","min","max")] = levin.est.df[,c("mean","min","max")]/AcPerHa
for (i in 1:n.w) {
levin.est.df$water_cutoff = rev(water.regimes)[i]
area.stats.df = rbind(area.stats.df, levin.est.df[,colnames(area.stats.df)])
}
# Simmons et al. (2024) estimate
sim.est.df = ls.df.area[which(ls.df.area$study == "Simmons et al. (2024)"),]
sim.est.df[,c("mean","min","max")] = sim.est.df[,c("mean","min","max")]/AcPerHa
for (i in 1:n.w) {
sim.est.df$water_cutoff = rev(water.regimes)[i]
area.stats.df = rbind(area.stats.df, sim.est.df[,colnames(area.stats.df)])
}
# Lane et al. (2025) estimate
lan.est.df = ls.df.area[which(ls.df.area$study == "Lane et al. (2025)"),]
lan.est.df[,c("mean","min","max")] = lan.est.df[,c("mean","min","max")]/AcPerHa
for (i in 1:n.w) {
lan.est.df$water_cutoff = rev(water.regimes)[i]
area.stats.df = rbind(area.stats.df, lan.est.df[,colnames(area.stats.df)])
}
# NRDC (2025) estimate
nrdc.est.df = ls.df.area[which(ls.df.area$study == "Devine et al. (2025)"),]
nrdc.est.df[,c("mean","min","max")] = nrdc.est.df[,c("mean","min","max")]/AcPerHa
for (i in 1:n.w) {
nrdc.est.df$water_cutoff = rev(water.regimes)[i]
if (i %in% c(1,2)) {
wr.df = nrdc.est.df[,c("water_cutoff","study","mean","min","mean")]
colnames(wr.df) = c("water_cutoff","study","mean","min","max")
} else {
wr.df = nrdc.est.df[,c("water_cutoff","study","max","max","max")]
colnames(wr.df) = c("water_cutoff","study","mean","min","max")
}
area.stats.df = rbind(area.stats.df, wr.df)
}
gold.est.df = read.csv("Area_Estimates/Previous_Studies/Gold_Estimates_Acres.csv", sep=",")
gold.est.df = gold.est.df[which(gold.est.df$type == "area"),-which(colnames(gold.est.df) == "type")]
gold.est.df[,c("mean","min","max")] = gold.est.df[,c("mean","min","max")]/AcPerHa
gold.est.df$study = "Gold (2024)"
area.stats.df = rbind(area.stats.df, gold.est.df[,colnames(area.stats.df)])
# step 9: calculate uncertainty ranges
area.stats.df$range = area.stats.df$max - area.stats.df$min
percent.stats.df$range = percent.stats.df$max - percent.stats.df$min
## step 10: plot non-WOTUS area and reason for lack of jurisdiction side by side (Figure 1)
# make dataframes for mean, min, and max areas for each group of reaons for loss of jurisdiction
area.mean.simple = area.df %>%
group_by(water_cutoff) %>%
summarize(`Behind levee` = mean(leveed_only + leveed_and_below_flood),
`Non-intersecting` = mean(non_intersect_only + non_intersect_and_below_flood),
`Behind levee & non-intersecting` = mean(leveed_and_non_intersect + leveed_non_intersect_below_flood),
`Below flood-frequency cutoff` = mean(below_flood_only))
area.min.simple = area.df %>%
group_by(water_cutoff) %>%
summarize(`Behind levee` = min(leveed_only + leveed_and_below_flood),
`Non-intersecting` = min(non_intersect_only + non_intersect_and_below_flood),
`Behind levee & non-intersecting` = min(leveed_and_non_intersect + leveed_non_intersect_below_flood),
`Below flood-frequency cutoff` = min(below_flood_only))
area.max.simple = area.df %>%
group_by(water_cutoff) %>%
summarize(`Behind levee` = max(leveed_only + leveed_and_below_flood),
`Non-intersecting` = max(non_intersect_only + non_intersect_and_below_flood),
`Behind levee & non-intersecting` = max(leveed_and_non_intersect + leveed_non_intersect_below_flood),
`Below flood-frequency cutoff` = max(below_flood_only))
area.mean.simple$stat = "Mean"
area.min.simple$stat = "Minimum"
area.max.simple$stat = "Maximum"
# melt mean, min, and max dataframes
area.mean.melt = melt(area.mean.simple,
id.variables=c("water_cutoff"),
value.name=c("Mean"),
variable.name=c("Reason for Lack\nof Federal Jurisdiction"))
area.min.melt = melt(area.min.simple,
id.variables=c("water_cutoff"),
value.name=c("Minimum"),
variable.name=c("Reason for Lack\nof Federal Jurisdiction"))
area.max.melt = melt(area.max.simple,
id.variables=c("water_cutoff"),
value.name=c("Maximum"),
variable.name=c("Reason for Lack\nof Federal Jurisdiction"))
# join mean, min, and max dataframes
area.comb.melt = right_join(area.mean.melt, area.min.melt, by=c("water_cutoff","Reason for Lack\nof Federal Jurisdiction"))
area.comb.melt = right_join(area.comb.melt, area.max.melt, by=c("water_cutoff","Reason for Lack\nof Federal Jurisdiction"))
area.melt = melt(area.comb.melt[,c("water_cutoff","Reason for Lack\nof Federal Jurisdiction","Mean","Minimum","Maximum")],
variable.name="stat",value.name="area")
# dataframe for state total (did not use)
state.df = data.frame("Total State Area" = total.state.area.ha)
colnames(state.df) = "Total State Area"
area.stats.df$water_label = rep(0, nrow(area.stats.df))
area.comb.melt$water_label = rep(0, nrow(area.comb.melt))
for (i in 1:n.w) { area.stats.df$water_label[which(area.stats.df$water_cutoff == water.regimes[i])] = water.reg.labels[i] }
for (i in 1:n.w) { area.comb.melt$water_label[which(area.comb.melt$water_cutoff == water.regimes[i])] = water.reg.labels[i] }
# Figure 1
studies = c("This study",sort(unique(area.stats.df$study))[1:5])
reason.order = c("Below flood-frequency cutoff","Non-intersecting","Behind levee","Behind levee & non-intersecting")
p1 = ggplot(area.stats.df, aes(x=mean,
y=factor(water_label, levels=water.reg.labels),
group=factor(study, levels=studies),
color=factor(study, levels=studies),
linetype=factor(study, levels=studies))) +
geom_line(linewidth=0.8) +
geom_ribbon(data = area.stats.df,
aes(xmin=min, xmax=max,
group=factor(study, levels=studies),
color=factor(study, levels=studies),
linetype=factor(study, levels=studies)),
alpha=0.1, linewidth=0.9) +
labs(y="Wetland Flood-Frequency Cutoff",
x="Non-WOTUS Wetland Area (ha)",
color="Source of Range Estimate",
linetype="Source of Range Estimate",
group="Source of Range Estimate") +
scale_x_continuous(limits=c(0,400000), labels=scales::comma) +
scale_color_manual(values=c("This study"="black",
"Gold (2024)"="goldenrod1",
"Lane et al. (2025)" = "green4",
"Levin et al. (2002)" = "darkorange2",
"NRDC (2025)" = "dodgerblue4",
"Simmons et al. (2024)"="purple")) +
scale_linetype_manual(values = c("This study"="solid",
"Gold (2024)"="longdash",
"Lane et al. (2025)"="twodash",
"Levin et al. (2002)"="dotted",
"NRDC (2025)"="dotdash",
"Simmons et al. (2024)"="dashed")) +
theme(text = element_text(size=15),
legend.key.size = unit(0.8,'cm'))
p2 = ggplot(area.comb.melt) +
geom_col_pattern(aes(x=Mean,
y = factor(water_label, levels=water.reg.labels),
fill = factor(`Reason for Lack\nof Federal Jurisdiction`, levels=reason.order),
pattern = factor(`Reason for Lack\nof Federal Jurisdiction`, levels=reason.order)),
pattern_fill="black",
pattern_density=0.1,
pattern_spacing=0.025) +
scale_pattern_manual(values=c("stripe","circle","crosshatch","none")) +
labs(y="",
x="Mean Non-WOTUS Wetland Area (ha)",
fill="Reason for Lack\nof Federal Jurisdiction",
pattern="Reason for Lack\nof Federal Jurisdiction") +
scale_x_continuous(limits=c(0,400000), labels=scales::comma) +
theme(text = element_text(size=15),
legend.key.size = unit(0.8,'cm'),
axis.text.y=element_blank())
p3 = p1 + p2
p3
p3
studies = c("This study",sort(unique(area.stats.df$study))[1:5])
reason.order = c("Below flood-frequency cutoff","Non-intersecting","Behind levee","Behind levee & non-intersecting")
p1 = ggplot(area.stats.df, aes(x=mean,
y=factor(water_label, levels=water.reg.labels),
group=factor(study, levels=studies),
color=factor(study, levels=studies),
linetype=factor(study, levels=studies))) +
geom_line(linewidth=0.8) +
geom_ribbon(data = area.stats.df,
aes(xmin=min, xmax=max,
group=factor(study, levels=studies),
color=factor(study, levels=studies),
linetype=factor(study, levels=studies)),
alpha=0.1, linewidth=0.9) +
labs(y="Wetland Flood-Frequency Cutoff",
x="Non-WOTUS Wetland Area (ha)",
color="Source of Range Estimate",
linetype="Source of Range Estimate",
group="Source of Range Estimate") +
scale_x_continuous(limits=c(0,400000), labels=scales::comma) +
scale_color_manual(values=c("This study"="black",
"Gold (2024)"="goldenrod1",
"Lane et al. (2025)" = "green4",
"Levin et al. (2002)" = "darkorange2",
"Devine et al. (2025)" = "dodgerblue4",
"Simmons et al. (2024)"="purple")) +
scale_linetype_manual(values = c("This study"="solid",
"Gold (2024)"="longdash",
"Lane et al. (2025)"="twodash",
"Levin et al. (2002)"="dotted",
"Devine et al. (2025)"="dotdash",
"Simmons et al. (2024)"="dashed")) +
theme(text = element_text(size=15),
legend.key.size = unit(0.8,'cm'))
p2 = ggplot(area.comb.melt) +
geom_col_pattern(aes(x=Mean,
y = factor(water_label, levels=water.reg.labels),
fill = factor(`Reason for Lack\nof Federal Jurisdiction`, levels=reason.order),
pattern = factor(`Reason for Lack\nof Federal Jurisdiction`, levels=reason.order)),
pattern_fill="black",
pattern_density=0.1,
pattern_spacing=0.025) +
scale_pattern_manual(values=c("stripe","circle","crosshatch","none")) +
labs(y="",
x="Mean Non-WOTUS Wetland Area (ha)",
fill="Reason for Lack\nof Federal Jurisdiction",
pattern="Reason for Lack\nof Federal Jurisdiction") +
scale_x_continuous(limits=c(0,400000), labels=scales::comma) +
theme(text = element_text(size=15),
legend.key.size = unit(0.8,'cm'),
axis.text.y=element_blank())
p3 = p1 + p2
p3
