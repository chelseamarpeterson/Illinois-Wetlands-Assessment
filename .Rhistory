?famd
>FAMD
?FAMD
install.packages("usethis")
library(usethis)
create_github_token()
path_to_nwi_data = "C:/Users/Chels/OneDrive - University of Illinois - Urbana/Illinois Wetlands Risk Assessment/Results/NWI_Data"
path_to_cejst = "C:/Users/Chels/OneDrive - University of Illinois - Urbana/Illinois Wetlands Risk Assessment/Databases/CEJST"
path_to_gitrepo = "C:/Users/Chels/OneDrive - University of Illinois - Urbana/Illinois Wetlands Risk Assessment/Public-Repo"
library(ggplot2)
library(reshape2)
library(dplyr)
library(rethinking)
################################################################################
# combine cejst data and unprotected wetland data for illinois
# read in CEJST data
setwd(path_to_cejst)
cj.df = read.csv("IL_CJEST_Data.csv")
# read in wetland area data
setwd(path_to_nwi_data)
area.df = read.csv("IL_WS_Step16_CJEST_Unprotected_Area.csv")
# water regimes
water.regimes = c("Permanently Flooded","Intermittently Exposed","Semipermanently Flooded",
"Seasonally Flooded/Saturated","Seasonally Flooded","Seasonally Saturated",
"Temporary Flooded","Intermittently Flooded")
water.reg.labels = c("Permanently Flooded","Intermittently Exposed","Semipermanently Flooded",
"Seasonally Flooded/Saturated","Seasonally Flooded","Seasonally Saturated",
"Temporarily Flooded","Intermittently Flooded")
n.w = length(water.regimes)
# protected counties
pro.cnties = paste(c("Cook","DeKalb","DuPage","Grundy","Kane","McHenry","Lake","Will"),"County",sep=" ")
sum(cj.df$CF %in% pro.cnties)
# add zeros to cejst polygons without area data
cjest.ids = sort(unique(cj.df$CJEST_ID))
n.cj = length(cjest.ids)
for (i in 1:n.cj) {
cj.id = cjest.ids[i]
geo.id = cj.df$GEOID10[which(cj.df$CJEST_ID == cj.id)]
if (!(cj.id %in% area.df$CJEST_ID)) {
new.df = data.frame(matrix(nrow=n.w, ncol=6))
colnames(new.df) = colnames(area.df)
new.df$GEOID10 = geo.id
new.df$CJEST_ID = cj.id
new.df$water_cutoff = water.regimes
new.df$mean_area = rep(0,n.w)
new.df$min_area = rep(0,n.w)
new.df$max_area = rep(0,n.w)
area.df = rbind(area.df, new.df)
}
}
length(unique(area.df$CJEST_ID))*8
# join area and cj df
colnames(cj.df)[which(colnames(cj.df) == "Area_Ha")] = "Tract_Ha"
area.cj.df = left_join(cj.df, area.df, by=c("CJEST_ID","GEOID10"))
# normalize wetland areas by census tract areas
area.cj.df$Tract_Normalized_Wetland_Area = area.cj.df$mean_area/area.cj.df$Tract_Ha
# add indicator for occurrence in a protected county
area.cj.df$cntyid = (area.cj.df$CF %in% pro.cnties)
sum(area.cj.df$cntyid)
# create new data frame for tracts outside counties with protections
area.cj.df.unprotected = area.cj.df[which(area.cj.df$cntyid==0),]
# names for groups of census tracts
groups = c("all","unprotected")
group.labels = c("All", "Unprotected")
n.g = length(groups)
# put dataframes into lists
area.dfs = list()
area.dfs[["all"]] = area.cj.df
area.dfs[["unprotected"]] = area.cj.df.unprotected
# calculate global mean for each set of tracts and normalize relative areas by global mean
global.means = list()
for (i in 1:n.g) {
grp = groups[i]
global.means[[grp]] = mean(area.dfs[[grp]]$Tract_Normalized_Wetland_Area)
area.dfs[[grp]]$Mean_Normalized_Wetland_Area = area.dfs[[grp]]$Tract_Normalized_Wetland_Area/global.means[[grp]]
}
################################################################################
# CEJST Analysis 1: fit Bayesian distributions to each indicator group
# indicator names
indicators = c("f","c","a","b","p","w")
ind.abrvs = c("Flood","Climate","Ag","Building","Population","Wildfire")
ind.cols = c("FLD_ET","N_CLT_EOMI","EAL_ET","EBL_ET","EPL_ET","WFR_ET")
# put normalized areas and indicators into list
area.lists = list()
for (i in 1:n.v) {
ind = indicators[i]
area.lists[[ind]] = list()
for (j in 1:n.g) {
grp = groups[j]
df = area.dfs[[grp]]
area.lists[[ind]][[grp]] = list(area_norm = as.vector(df$Mean_Normalized_Wetland_Area),
cutoff_id = as.integer(factor(df$water_cutoff)),
risk_id = as.integer(factor(df[,ind.cols[i]])))
}
}
path_to_nwi_data = "C:/Users/Chels/OneDrive - University of Illinois - Urbana/Illinois Wetlands Risk Assessment/Results/NWI_Data"
path_to_cejst = "C:/Users/Chels/OneDrive - University of Illinois - Urbana/Illinois Wetlands Risk Assessment/Databases/CEJST"
path_to_gitrepo = "C:/Users/Chels/OneDrive - University of Illinois - Urbana/Illinois Wetlands Risk Assessment/Public-Repo"
library(ggplot2)
library(reshape2)
library(dplyr)
library(rethinking)
################################################################################
# combine cejst data and unprotected wetland data for illinois
# read in CEJST data
setwd(path_to_cejst)
cj.df = read.csv("IL_CJEST_Data.csv")
# read in wetland area data
setwd(path_to_nwi_data)
area.df = read.csv("IL_WS_Step16_CJEST_Unprotected_Area.csv")
# water regimes
water.regimes = c("Permanently Flooded","Intermittently Exposed","Semipermanently Flooded",
"Seasonally Flooded/Saturated","Seasonally Flooded","Seasonally Saturated",
"Temporary Flooded","Intermittently Flooded")
water.reg.labels = c("Permanently Flooded","Intermittently Exposed","Semipermanently Flooded",
"Seasonally Flooded/Saturated","Seasonally Flooded","Seasonally Saturated",
"Temporarily Flooded","Intermittently Flooded")
n.w = length(water.regimes)
# protected counties
pro.cnties = paste(c("Cook","DeKalb","DuPage","Grundy","Kane","McHenry","Lake","Will"),"County",sep=" ")
sum(cj.df$CF %in% pro.cnties)
# add zeros to cejst polygons without area data
cjest.ids = sort(unique(cj.df$CJEST_ID))
n.cj = length(cjest.ids)
for (i in 1:n.cj) {
cj.id = cjest.ids[i]
geo.id = cj.df$GEOID10[which(cj.df$CJEST_ID == cj.id)]
if (!(cj.id %in% area.df$CJEST_ID)) {
new.df = data.frame(matrix(nrow=n.w, ncol=6))
colnames(new.df) = colnames(area.df)
new.df$GEOID10 = geo.id
new.df$CJEST_ID = cj.id
new.df$water_cutoff = water.regimes
new.df$mean_area = rep(0,n.w)
new.df$min_area = rep(0,n.w)
new.df$max_area = rep(0,n.w)
area.df = rbind(area.df, new.df)
}
}
length(unique(area.df$CJEST_ID))*8
# join area and cj df
colnames(cj.df)[which(colnames(cj.df) == "Area_Ha")] = "Tract_Ha"
area.cj.df = left_join(cj.df, area.df, by=c("CJEST_ID","GEOID10"))
# normalize wetland areas by census tract areas
area.cj.df$Tract_Normalized_Wetland_Area = area.cj.df$mean_area/area.cj.df$Tract_Ha
# add indicator for occurrence in a protected county
area.cj.df$cntyid = (area.cj.df$CF %in% pro.cnties)
sum(area.cj.df$cntyid)
# create new data frame for tracts outside counties with protections
area.cj.df.unprotected = area.cj.df[which(area.cj.df$cntyid==0),]
# names for groups of census tracts
groups = c("all","unprotected")
group.labels = c("All", "Unprotected")
n.g = length(groups)
# put dataframes into lists
area.dfs = list()
area.dfs[["all"]] = area.cj.df
area.dfs[["unprotected"]] = area.cj.df.unprotected
# calculate global mean for each set of tracts and normalize relative areas by global mean
global.means = list()
for (i in 1:n.g) {
grp = groups[i]
global.means[[grp]] = mean(area.dfs[[grp]]$Tract_Normalized_Wetland_Area)
area.dfs[[grp]]$Mean_Normalized_Wetland_Area = area.dfs[[grp]]$Tract_Normalized_Wetland_Area/global.means[[grp]]
}
################################################################################
# CEJST Analysis 1: fit Bayesian distributions to each indicator group
# indicator names
indicators = c("f","c","a","b","p","w")
ind.abrvs = c("Flood","Climate","Ag","Building","Population","Wildfire")
n.v = length(indicators)
ind.cols = c("FLD_ET","N_CLT_EOMI","EAL_ET","EBL_ET","EPL_ET","WFR_ET")
# put normalized areas and indicators into list
area.lists = list()
for (i in 1:n.v) {
ind = indicators[i]
area.lists[[ind]] = list()
for (j in 1:n.g) {
grp = groups[j]
df = area.dfs[[grp]]
area.lists[[ind]][[grp]] = list(area_norm = as.vector(df$Mean_Normalized_Wetland_Area),
cutoff_id = as.integer(factor(df$water_cutoff)),
risk_id = as.integer(factor(df[,ind.cols[i]])))
}
}
## fit models for normalized area
set.seed(314)
m.list = list()
for (i in 1:n.v) {
ind = indicators[i]
m.list[[ind]] = list()
for (j in 1:n.g) {
grp = groups[j]
area.list.ij = area.lists[[ind]][[grp]]
m.ij = ulam(alist(area_norm ~ normal(mu, sigma),
log(mu) <- a[cutoff_id,risk_id],
matrix[cutoff_id,risk_id]: a ~ dnorm(0,1),
sigma ~ dexp(1)),
data=area.list.ij, chains=5, log_lik=T)
m.list[[ind]][[grp]] = m.ij
# re-scale posterior estimates
exp.a.ij = exp(extract.samples(m.ij)$a)*global.means[[grp]]
# calculate posterior difference and melt dataframe
diff.ij = exp.a.ij[,,2] - exp.a.ij[,,1]
colnames(diff.ij) = levels(factor(area.dfs[[grp]]$water_cutoff))
# write to file
write.csv(diff.ij,
paste("CEJST_Analysis/Posteriors/",paste(ind.abrvs[i],group.labels[j],"Indicator_PostDiff.csv",sep="_"),sep=""),
row.names=F)
}
}
setwd(path_to_gitrepo)
write.csv(diff.ij,
paste("CEJST_Analysis/Posteriors/",paste(ind.abrvs[i],group.labels[j],"Indicator_PostDiff.csv",sep="_"),sep=""),
row.names=F)
set.seed(314)
m.list = list()
for (i in 1:n.v) {
ind = indicators[i]
m.list[[ind]] = list()
if (i > 1) {
s.i = 1
} else {
s.i = n.g
}
for (j in s.i:n.g) {
grp = groups[j]
area.list.ij = area.lists[[ind]][[grp]]
m.ij = ulam(alist(area_norm ~ normal(mu, sigma),
log(mu) <- a[cutoff_id,risk_id],
matrix[cutoff_id,risk_id]: a ~ dnorm(0,1),
sigma ~ dexp(1)),
data=area.list.ij, chains=5, log_lik=T)
m.list[[ind]][[grp]] = m.ij
# re-scale posterior estimates
exp.a.ij = exp(extract.samples(m.ij)$a)*global.means[[grp]]
# calculate posterior difference and melt dataframe
diff.ij = exp.a.ij[,,2] - exp.a.ij[,,1]
colnames(diff.ij) = levels(factor(area.dfs[[grp]]$water_cutoff))
# write to file
write.csv(diff.ij,
paste("CEJST_Analysis/Posteriors/",paste(ind.abrvs[i],group.labels[j],"Indicator_PostDiff.csv",sep="_"),sep=""),
row.names=F)
}
}
